include:
  - remote: 'https://gitlab.com/cscs-ci/recipes/-/raw/master/templates/v2/.ci-ext.yml'

stages:
  - build_base
  - build_app
  - build_multiarch
  - test

# TARGET must be any of  {daint-gpu daint-mc alps-zen2 alps-a100 alps-mi200 alps-gh200 alps-mi300a}

build_base_image_x86_64:
  extends: [.container-builder-cscs-zen2, .dynamic-image-name]
  stage: build_base
  variables:
    DOCKERFILE: .cscs-ci-ext/Dockerfile.base
    WATCH_FILECHANGES: '.cscs-ci-ext/Dockerfile.base'
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/arbor/baseimg-x86_64
    CSCS_BUILD_IN_MEMORY: TRUE
    CSCS_REBUILD_POLICY: "if-not-exists"
    DOCKER_BUILD_ARGS: '["IMG_BASE=ghcr.io/eth-cscs/docker-ci-ext/base-containers/spack-base:spack0.21.0-ubuntu22.04-cpu", "IMG_HELPER=ghcr.io/eth-cscs/docker-ci-ext/base-containers/spack-helper:ubuntu22.04-cpu", "TARGET=alps-zen2"]'

build_base_image_aarch64:
  extends: [.container-builder-cscs-gh200, .dynamic-image-name]
  stage: build_base
  variables:
    DOCKERFILE: .cscs-ci-ext/Dockerfile.base
    WATCH_FILECHANGES: '.cscs-ci-ext/Dockerfile.base'
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/arbor/baseimg-aarch64
    CSCS_BUILD_IN_MEMORY: TRUE
    CSCS_REBUILD_POLICY: "if-not-exists"
    DOCKER_BUILD_ARGS: '["IMG_BASE=ghcr.io/eth-cscs/docker-ci-ext/base-containers/spack-base:spack0.21.0-ubuntu22.04-cuda12.4.1", "IMG_HELPER=ghcr.io/eth-cscs/docker-ci-ext/base-containers/spack-helper:ubuntu22.04-cuda12.4.1", "TARGET=alps-gh200"]'

build_app_image_x86_64:
  extends: .container-builder-cscs-zen2
  stage: build_app
  needs:
  - job: build_base_image_x86_64
    artifacts: true
  variables:
    DOCKERFILE: .cscs-ci-ext/Dockerfile.app
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/arbor/appimg-x86_64:$CI_COMMIT_SHORT_SHA
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=$BASE_IMAGE", "CXX_FLAGS=-march=znver2"]'

build_app_image_aarch64:
  extends: .container-builder-cscs-gh200
  stage: build_app
  needs:
  - job: build_base_image_aarch64
    artifacts: true
  variables:
    DOCKERFILE: .cscs-ci-ext/Dockerfile.app
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/arbor/appimg-aarch64:$CI_COMMIT_SHORT_SHA
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=$BASE_IMAGE", "CXX_FLAGS=-mcpu=neoverse-v2 -mtune=neoverse-v2", "GPU=cuda", "GPU_ARCH=90"]'

build_multiarch_image:
  extends: .make-multiarch-image
  stage: build_multiarch
  variables:
    PERSIST_IMAGE_NAME_X86_64: "$CSCS_REGISTRY_PATH/arbor/appimg-x86_64:$CI_COMMIT_SHORT_SHA"
    PERSIST_IMAGE_NAME_AARCH64: "$CSCS_REGISTRY_PATH/arbor/appimg-aarch64:$CI_COMMIT_SHORT_SHA"
    PERSIST_IMAGE_NAME: "$CSCS_REGISTRY_PATH/arbor/appimg:$CI_COMMIT_SHORT_SHA"

    # 2 sockets wuth 64 cores each (16 cores per numa node), can be hyperthreaded
test_x86_64:
  stage: test
  extends: .container-runner-eiger-mc
  image: $CSCS_REGISTRY_PATH/arbor/appimg:$CI_COMMIT_SHORT_SHA
  script:
    - cd /arbor.src
    - build/bin/unit-modcc
    - build/bin/unit-local
    - build/bin/unit
    - scripts/run_cpp_examples.sh
    - python -m venv --system-site-packages /arbor.install
    - source /arbor.install/bin/activate
    - python -m unittest discover -v -s python
    - scripts/run_python_examples.sh
    - scripts/test_executables.sh
    - deactivate
  variables:
    SLURM_CONSTRAINT: mc
    SLURM_JOB_NUM_NODES: 1
    SLURM_NTASKS: 1
    SLURM_CPUS_PER_TASK: 128
    SLURM_THREADS_PER_CORE: 1
    SLURM_CPU_BIND_VERBOSE: "verbose"
    SLURM_TIMELIMIT: "00:30:00"
    USE_MPI: "NO"

test_aarch64:
  stage: test
  extends: .container-runner-todi-gh200
  image: $CSCS_REGISTRY_PATH/arbor/appimg:$CI_COMMIT_SHORT_SHA
  script:
    - cd /arbor.src
    - build/bin/unit-modcc
    - build/bin/unit-local
    - build/bin/unit
    - scripts/run_cpp_examples.sh
    - python -m venv --system-site-packages /arbor.install
    - source /arbor.install/bin/activate
    - python -m unittest discover -v -s python
    - scripts/run_python_examples.sh
    - scripts/test_executables.sh
    - deactivate
  variables:
    SLURM_JOB_NUM_NODES: 1
    SLURM_NTASKS: 1
    SLURM_CPUS_PER_TASK: 72
    SLURM_CPU_BIND_VERBOSE: "verbose"
    SLURM_TIMELIMIT: "00:30:00"
    USE_MPI: "NO"
